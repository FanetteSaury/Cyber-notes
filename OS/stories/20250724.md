## How caches can go wrong ?
![[bbg_cache_breakdown.gif]]
>[!def]
Redis is an incredibly fast, in-memory data store frequently used as a cache

Think of a cache like a **super-fast, temporary storage space** that sits between your program and a slower, more permanent storage like a database.

- **Why use a cache?** Because getting data from the cache is way faster than going to the database every single time. It's like having frequently used tools right on your desk instead of walking to the storage room every time you need a screwdriver.
    

Now, even though caches are awesome, they're not perfect. Just like any system, they can go wrong, and when they do, your application can slow down, crash, or just behave weirdly. The "cyber" aspect often comes in when these "wrong" behaviors are exploited or cause system instabdefinitionility that attackers might leverage, but for now, let's focus on the operational issues.

Let's break down those 4 common problems, imagining your program is trying to get data from the cache, and if it's not there, it goes to the database.

---

### How Cache Systems Can Go Wrong: Explained for a Programmer

#### 1. Thunder Herd Problem (Imagine a Stampede!)

**What it is:** Imagine you have a bunch of popular items in your online store, and you've put them all in the cache. You set them all to expire from the cache at exactly the same time, say, in 1 hour.

When that hour is up, _all_ those items suddenly disappear from the cache. Now, if a bunch of users try to view these popular items at the same moment, your program can't find them in the cache. What does it do? It **rushes to the database** for _every single one_ of those requests.

If there are thousands or millions of these requests hitting the database all at once, it's like a huge stampede. The database, which is slower, gets completely overwhelmed, slows down, or even crashes. Your users see "loading..." or error messages.

**Solutions:**

- **Stagger Expiry Times (Add a Random Delay):** Instead of "expire in exactly 60 minutes," you set it to "expire in 60 minutes PLUS a random number of seconds between 1 and 30." This spreads out when items leave the cache, so they don't all hit the database simultaneously.
    
- **Prioritize Data (Core vs. Non-Core):** If the cache is struggling, you might tell your program, "Only go to the database for the _really important_ data (like customer orders). For less critical stuff (like product recommendations), just tell the user 'not available' until the cache is healthy again." This protects the database from being swamped by less critical requests.
    

---

#### 2. Cache Penetration (The "Ghost" Data Problem)

**What it is:** Imagine someone is trying to look up an item in your store, but they type in a completely fake or non-existent product ID, like "XYZ123".

Your program first checks the cache for "XYZ123". It's not there. Then, it goes to the database to look for "XYZ123". It's not there either. Since it couldn't find it, it can't put it in the cache for next time.

If an attacker (or just a very buggy program) sends millions of requests for non-existent items, every single one of those requests has to go all the way to the database, because the cache will _never_ have it. This puts a huge, pointless load on both your cache and your database.

**Solutions:**

- **Cache "Null" Values:** If your program looks for "XYZ123" in the database and finds nothing, instead of just giving up, it puts a special "this doesn't exist" marker (a "null" value) for "XYZ123" into the cache. So, next time someone asks for "XYZ123", your program sees the "null" in the cache and knows _immediately_ not to bother the database.
    
- **Bloom Filter:** This is a fancy data structure. Imagine a super-fast, probabilistic "pre-check" list. Before your program even tries the cache or the database, it asks the Bloom Filter, "Hey, does 'XYZ123' _possibly_ exist?" If the Bloom Filter says "No, definitely not," your program stops right there and doesn't bother the cache or database. It's not 100% accurate (it can sometimes say "yes" when the item _doesn't_ exist, but never "no" when it _does_), but it's incredibly fast at filtering out most non-existent requests.
    

---

#### 3. Cache Breakdown (The "Super Popular Item Suddenly Vanishes" Problem)

**What it is:** This is very similar to the "Thunder Herd" but focuses on **one or a few _super-hot_ items**. Think of the absolute most popular product on your site. If the cache for _just this one item_ expires, and hundreds of thousands of users are trying to access it _right now_, then all those requests will suddenly bypass the cache and hit the database for that single item.

Even if it's just one key, if it's responsible for 80% of your traffic, its expiration can bring down the database just as effectively as a stampede of many keys.

**Solutions:**

- **No Expiration for Hot Keys (or Very Long Expiration):** For the absolutely hottest, most critical data, you might decide _not_ to set an expiration time for it in the cache. It stays there indefinitely, or until you manually update it. This prevents the sudden flood to the database. (Of course, you need a way to refresh it if the underlying data changes in the database).
    

---

#### 4. Cache Crash (The "Cache Went Offline" Problem)

**What it is:** This is the simplest but perhaps most catastrophic. What if the entire cache system itself (the server it's running on, or the software) completely fails and goes offline?

Now, _every single request_ that was supposed to go to the cache has no choice but to go directly to the database. Since the database isn't built to handle the entire load of your application by itself (that's why you have a cache!), it will quickly get overwhelmed and crash. Your entire application can go down.

**Solutions:**

- **Circuit Breaker:** Imagine a circuit breaker in your house. If an appliance tries to draw too much power and threatens to blow a fuse, the circuit breaker "trips" and cuts off power to protect the system. In software, if your program detects that the cache is down (or very slow), the circuit breaker "trips." Instead of trying endlessly to connect to the dead cache and then overwhelming the database, it simply says, "The cache is down, I can't serve this request right now" or "Please try again later." It protects the database from being hammered unnecessarily.
    
- **Cache Cluster (Redundancy):** Instead of having just one cache server, you set up a **cluster** of multiple cache servers. If one cache server crashes, the other servers in the cluster automatically take over. This is like having backup generators or multiple power lines â€“ if one fails, the others keep things running, significantly improving the availability of your cache system.
    

---

These issues are very real in production environments and often require careful planning and implementation to avoid application downtime and poor user experience. As a programmer, understanding these failure modes will help you design more robust and reliable systems.
